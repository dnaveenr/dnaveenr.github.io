<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Desanur Naveen Reddy</title>
  
  <meta name="author" content="D. Naveen Reddy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Naveen Reddy Desanur</name>
              </p>
              <p>I am a machine learning engineer at <a href="https://www.sensara.tv">Sensara Technologies</a>, where I work on computer vision, deep learning applications.
              </p>
              <p>
                At Sensara I've worked on Channel Logo Recognition, Image Quality Analysis, Image Similarity based on unsupervised techniques such as clustering. I did my Bachelers in Computer Science & Engineering at <a herf="https://www.pes.edu/">PES University, Bangalore</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:dnaveen356@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vase_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>arXiv</em>, 2020  
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
        /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p>
            </td>
          </tr> 
    
          <tr onmouseout="lighthouse_stop()" onmouseover="lighthouse_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lh_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/rings_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/rings.png' width="160">
              </div>
              <script type="text/javascript">
                function lighthouse_start() {
                  document.getElementById('lh_image').style.opacity = "1";
                }

                function lighthouse_stop() {
                  document.getElementById('lh_image').style.opacity = "0";
                }
                lighthouse_stop()
              </script>
            </td>
            

          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='aperture_image'><img src='images/aperture_after.jpg'></div>
                <img src='images/aperture_before.jpg'>
              </div>
              <script type="text/javascript">
                function aperture_start() {
                  document.getElementById('aperture_image').style.opacity = "1";
                }

                function aperture_stop() {
                  document.getElementById('aperture_image').style.opacity = "0";
                }
                aperture_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1MpvxcW7OTJP321QL_q4ZLQ8D653bZZzy/view?usp=sharing">
                <papertitle>Aperture Supervision for Monocular Depth Estimation</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul P. Srinivasan</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2018
              <br>
              <a href="https://github.com/google/aperture_supervision">code</a> /
              <a href="data/Srinivasan2018.bib">bibtex</a>
              <p></p>
              <p>Varying a camera's aperture provides a supervisory signal that can teach a neural network to do monocular depth estimation.</p>
            </td>
          </tr>

          <tr onmouseout="deepburst_stop()" onmouseover="deepburst_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='deepburst_image'><img src='images/deepburst_after.png'></div>
                <img src='images/deepburst_before.png'>
              </div>
              <script type="text/javascript">
                function deepburst_start() {
                  document.getElementById('deepburst_image').style.opacity = "1";
                }

                function deepburst_stop() {
                  document.getElementById('deepburst_image').style.opacity = "0";
                }
                deepburst_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1GAH8ijyZ7GnoBnQFANEzdXinHrE4vvXn/view?usp=sharing">
                <papertitle>Burst Denoising with Kernel Prediction Networks</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
              <a href="http://www.dsharlet.com/">Dillon Sharlet</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>, Robert Carroll
              <br>
              <em>CVPR</em>, 2018 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
              <a href="https://drive.google.com/file/d/1aqk3Q-L2spjLZh2yRWKUWIDcZkGjQ7US/view?usp=sharing">supplement</a> /
              <a href="https://github.com/google/burst-denoising">code</a> /
              <a href="data/Mildenhall2018.bib">bibtex</a>
              <p></p>
              <p>We train a network to predict linear kernels that denoise noisy bursts from cellphone cameras.</p>
            </td>
          </tr>

          <tr onmouseout="friendly_stop()" onmouseover="friendly_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='friendly_image'><img src='images/friendly_after.png'></div>
                <img src='images/friendly_before.png'>
              </div>
              <script type="text/javascript">
                function friendly_start() {
                  document.getElementById('friendly_image').style.opacity = "1";
                }

                function friendly_stop() {
                  document.getElementById('friendly_image').style.opacity = "0";
                }
                friendly_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1w_0djhL0QgC_fbehnJ0c-J23_kW_420p/view?usp=sharing">
                <papertitle>A Hardware-Friendly Bilateral Solver for Real-Time Virtual Reality Video</papertitle>
              </a>
              <br>
              <a href="https://homes.cs.washington.edu/~amrita/">Amrita Mazumdar</a>, <a href="http://homes.cs.washington.edu/~armin/">Armin Alaghi</a>, <strong>Jonathan T. Barron</strong>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a>, <a href="https://homes.cs.washington.edu/~oskin/">Mark Oskin</a>, <a href="http://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>
              <br>
              <em>High-Performance Graphics (HPG)</em>, 2017
              <br>
              <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>
              <p></p>
              <p>A reformulation of the bilateral solver can be implemented efficiently on GPUs and FPGAs.</p>
            </td>
          </tr>

          <tr onmouseout="hdrnet_stop()" onmouseover="hdrnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hdrnet_image'><img src='images/hdrnet_after.jpg'></div>
                <img src='images/hdrnet_before.jpg'>
              </div>
              <script type="text/javascript">
                function hdrnet_start() {
                  document.getElementById('hdrnet_image').style.opacity = "1";
                }

                function hdrnet_stop() {
                  document.getElementById('hdrnet_image').style.opacity = "0";
                }
                hdrnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1jQY3CTMnLX7PeGUzYLso9H1eCsZyWbwg/view?usp=sharing">
                <papertitle>Deep Bilateral Learning for Real-Time Image Enhancement</papertitle>
              </a>
              <br>
              <a href="http://www.mgharbi.com">Micha&euml;l Gharbi</a>, <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="https://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>, <a href="http://people.csail.mit.edu/fredo/">Fr&eacute;do Durand </a>
              <br>
              <em>SIGGRAPH</em>, 2017
              <br>
              <a href="https://groups.csail.mit.edu/graphics/hdrnet/">project page</a> /
              <a href="https://www.youtube.com/watch?v=GAe0qKKQY_I">video</a> /
              <a href="data/GharbiSIGGRAPH2017.bib">bibtex</a> /
              <a href="http://news.mit.edu/2017/automatic-image-retouching-phone-0802">p</a><a href="https://www.wired.com/story/googles-new-algorithm-perfects-photos-before-you-even-take-them/">r</a><a href="https://petapixel.com/2017/08/02/new-ai-can-retouch-photos-snap/">e</a><a href="https://www.theverge.com/2017/8/2/16082272/google-mit-retouch-photos-machine-learning">s</a><a href="http://gizmodo.com/clever-camera-app-uses-deep-learning-to-perfectly-retou-1797474282">s</a>
              <p></p>
              <p>By training a deep network in bilateral space we can learn a model for high-resolution and real-time image enhancement.</p>
            </td>
          </tr>

          <tr onmouseout="ffcc_stop()" onmouseover="ffcc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ffcc_image'><img src='images/ffcc_after.jpg'></div>
                <img src='images/ffcc_before.jpg'>
              </div>
              <script type="text/javascript">
                function ffcc_start() {
                  document.getElementById('ffcc_image').style.opacity = "1";
                }

                function ffcc_stop() {
                  document.getElementById('ffcc_image').style.opacity = "0";
                }
                ffcc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1VDWAS7HgiufTNPP7CQY00KmJP71QIZAy/view?usp=sharing">
                <papertitle>Fast Fourier Color Constancy</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, Yun-Ta Tsai
              <br>
              <em>CVPR</em>, 2017
              <br>
              <a href="https://drive.google.com/file/d/1b5zdR5UYPTkXa2UgiLhi-PP89bzINJSR/view?usp=sharing">supplement</a> /
              <a href="https://youtu.be/rZCXSfl13rY">video</a> /
              <a href="data/BarronTsaiCVPR2017.bib">bibtex</a> /
              <a href="https://github.com/google/ffcc">code</a> /
              <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmWkJQMlFPSFNzbEk">output</a> /
              <a href="https://blog.google/products/photos/six-tips-make-your-photos-pop/">blog post</a> /
              <a href="https://9to5google.com/2017/03/03/google-photos-auto-white-balance/">p</a><a href="https://www.engadget.com/2017/03/03/google-photos-automatically-fixes-your-pictures-white-balance/">r</a><a href="https://lifehacker.com/google-photos-will-now-automatically-adjust-the-white-b-1793009155">e</a><a href="https://petapixel.com/2017/03/06/google-photos-will-now-automatically-white-balance-snapshots/">s</a><a href="http://www.theverge.com/2017/3/3/14800062/google-photos-auto-white-balance-android">s</a>
              <p></p>
              <p>Color space can be aliased, allowing white balance models to be learned and evaluated in the frequency domain. This improves accuracy by 13-20% and speed by 250-3000x.</p>
              <p>This technology is used by <a href="https://store.google.com/product/pixel_compare">Google Pixel</a>, <a href="https://photos.google.com/">Google Photos</a>, and <a href="https://www.google.com/maps">Google Maps</a>.</p>
            </td>
          </tr>

          <tr onmouseout="jump_stop()" onmouseover="jump_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='jump_image'><img src='images/jump_anim.gif'></div>
                <img src='images/jump_still.png'>
              </div>
              <script type="text/javascript">
                function jump_start() {
                  document.getElementById('jump_image').style.opacity = "1";
                }

                function jump_stop() {
                  document.getElementById('jump_image').style.opacity = "0";
                }
                jump_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1RBnTrtzqmuO8uj3GQaR5vBJZjIC3Jxjn/view?usp=sharing">
                <papertitle>Jump: Virtual Reality Video</papertitle>
              </a>
              <br>
              <a href="http://mi.eng.cam.ac.uk/~ra312/">Robert Anderson</a>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <strong>Jonathan T. Barron</strong>, <a href="https://mediatech.aalto.fi/~janne/index.php">Janne Kontkanen</a>, <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>, <a href="http://carlos-hernandez.org/">Carlos Hern&aacutendez</a>, <a href="https://homes.cs.washington.edu/~sagarwal/">Sameer Agarwal</a>, <a href="https://homes.cs.washington.edu/~seitz/">Steven M Seitz</a>
              <br>
              <em>SIGGRAPH Asia</em>, 2016
              <br>
              <a href="https://drive.google.com/file/d/11D4eCDXqqFTtZT0WS2COJE0hsAN3QEww/view?usp=sharing">supplement</a> /
              <a href="https://www.youtube.com/watch?v=O0qUYynupTI">video</a> /
              <a href="data/Anderson2016.bib">bibtex</a> /
              <a href="https://blog.google/products/google-vr/jump-using-omnidirectional-stereo-vr-video/">blog post</a>
              <p></p>
              <p>Using computer vision and a ring of cameras, we can make video for virtual reality headsets that is both stereo and 360&deg;.</p>
              <p>This technology is used by <a href="https://vr.google.com/jump/">Jump</a>. </p>
            </td>
          </tr>

          <tr onmouseout="hdrp_stop()" onmouseover="hdrp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hdrp_image'><img src='images/hdrp_after.jpg'></div>
                <img src='images/hdrp_before.jpg'>
              </div>
              <script type="text/javascript">
                function hdrp_start() {
                  document.getElementById('hdrp_image').style.opacity = "1";
                }

                function hdrp_stop() {
                  document.getElementById('hdrp_image').style.opacity = "0";
                }
                hdrp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1SSSmVHWbMQ7sZMOredSVWVJXbXobkyzA/view?usp=sharing">
                <papertitle>Burst Photography for High Dynamic Range and Low-Light Imaging on Mobile Cameras</papertitle>
              </a>
              <br>
              <a href="http://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>, <a href="http://www.dsharlet.com/">Dillon Sharlet</a>, <a href="http://www.geisswerks.com/">Ryan Geiss</a>, <a href="http://people.csail.mit.edu/abadams/">Andrew Adams</a>, <strong>Jonathan T. Barron</strong>, Florian Kainz, <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>, <a href="http://graphics.stanford.edu/~levoy/">Marc Levoy</a>
              <br>
              <em>SIGGRAPH Asia</em>, 2016
              <br>
              <a href="http://hdrplusdata.org/">project page</a> /
              <a href="https://drive.google.com/open?id=15EUuSDi1BtHUgQCaiooVrD44qYKIC3vx">supplement</a> /
              <a href="data/Hasinoff2016.bib">bibtex</a>
              <p></p>
              <p>Mobile phones can take beautiful photographs in low-light or high dynamic range environments by aligning and merging a burst of images.</p>
              <p>This technology is used by the <a href="https://research.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">Nexus HDR+</a> feature.</p>
            </td>
          </tr>

          <tr onmouseout="bs_stop()" onmouseover="bs_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='bs_image'><img src='images/BS_after.jpg'></div>
                <img src='images/BS_before.jpg'>
              </div>
              <script type="text/javascript">
                function bs_start() {
                  document.getElementById('bs_image').style.opacity = "1";
                }

                function bs_stop() {
                  document.getElementById('bs_image').style.opacity = "0";
                }
                bs_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1zFzCaFwkGK1EGmJ_KEqb-ZsRJhfUKN2S/view?usp=sharing">
                <papertitle>The Fast Bilateral Solver</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>
              <br>
              <em>ECCV</em>, 2016 &nbsp <font color="red"><strong>(Best Paper Honorable Mention)</strong></font>
              <br>
              <a href="http://arxiv.org/abs/1511.03296">arXiv</a> /
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmdEREcjhlSXM2NGs/view?usp=sharing">supplement</a> /
              <a href="data/BarronPooleECCV2016.bib">bibtex</a> /
              <a href="http://videolectures.net/eccv2016_barron_bilateral_solver/">video (they messed up my slides, use &rarr;)</a> /
              <a href="https://drive.google.com/file/d/19x1AeN0PFus6Pjrd8nR-vCmJ6bNEefsC/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/1p9nduiymK9jUh7WfwlsMjBfW8RoNe_61/view?usp=sharing">PDF</a>) /
              <a href="https://github.com/poolio/bilateral_solver">code</a> /
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmaDI3bm5VeDRxams/view?usp=sharing">depth super-res results</a> /
              <a href="data/BarronPooleECCV2016_reviews.txt">reviews</a>
              <p></p>
              <p>Our solver smooths things better than other filters and faster than other optimization algorithms, and you can backprop through it.</p>
            </td>
          </tr>

          <tr onmouseout="diverdi_stop()" onmouseover="diverdi_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='diverdi_image'><img src='images/diverdi_after.jpg'></div>
                <img src='images/diverdi_before.jpg'>
              </div>
              <script type="text/javascript">
                function diverdi_start() {
                  document.getElementById('diverdi_image').style.opacity = "1";
                }

                function diverdi_stop() {
                  document.getElementById('diverdi_image').style.opacity = "0";
                }
                diverdi_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1mmT-LuK_eBZsl3qp4-fAshEPdgfbgvNE/view?usp=sharing">
                <papertitle>Geometric Calibration for Mobile, Stereo, Autofocus Cameras</papertitle>
              </a>
              <br>
              <a href="http://www.stephendiverdi.com/">Stephen DiVerdi</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>WACV</em>, 2016
              <br>
              <a href="data/Diverdi2016.bib">bibtex</a>
              <p></p>
              <p>Standard techniques for stereo calibration don't work for cheap mobile cameras.</p>
            </td>
          </tr>

          <tr onmouseout="dt_stop()" onmouseover="dt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dt_image'><img src='images/DT_edge.jpg'></div>
                <img src='images/DT_image.jpg'>
              </div>
              <script type="text/javascript">
                function dt_start() {
                  document.getElementById('dt_image').style.opacity = "1";
                }

                function dt_stop() {
                  document.getElementById('dt_image').style.opacity = "0";
                }
                dt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/178Xj2PZ1w6hZJpucU-TiZOoCemJmvsVQ/view?usp=sharing">
                <papertitle>Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform</papertitle>
              </a>
              <br>
              <em>CVPR</em>, 2016
              <br>
              <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="http://ttic.uchicago.edu/~gpapan/">George Papandreou</a>, <a href="http://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a href="http://www.stat.ucla.edu/~yuille/">Alan L. Yuille</a>
              <br>
              <a href="data/Chen2016.bib">bibtex</a> /
              <a href="http://liangchiehchen.com/projects/DeepLab.html">project page</a> /
              <a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2">code</a>
              <p></p>
              <p>By integrating an edge-aware filter into a convolutional neural network we can learn an edge-detector while improving semantic segmentation.</p>
            </td>
          </tr>

          <tr onmouseout="ccc_stop()" onmouseover="ccc_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_image'><img src='images/ccc_after.jpg'></div>
                <img src='images/ccc_before.jpg'>
              </div>
              <script type="text/javascript">
                function ccc_start() {
                  document.getElementById('ccc_image').style.opacity = "1";
                }

                function ccc_stop() {
                  document.getElementById('ccc_image').style.opacity = "0";
                }
                ccc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1id74VNDL8ACrrWf6vYgN2M4kS8gd4n7w/view?usp=sharing">
                <papertitle>Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>ICCV</em>, 2015
              <br>
              <a href="https://drive.google.com/file/d/1vO3sVOMihmpNqsuASeR46Y_iME0lOANR/view?usp=sharing">supplement</a> / <a href="data/BarronICCV2015.bib">bibtex</a> / <a href="https://youtu.be/saHwKY9rfx0">video</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmalBNUzlENUJSVDg/view?usp=sharing">mp4</a>)
              <p></p>
              <p>By framing white balance as a chroma localization task we can discriminatively learn a color constancy model that beats the state-of-the-art by 40%.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Shelhamer2015.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1stygV71uBruD7Ck9CaAQr7nREvr3DtUL/view?usp=sharing">
                <papertitle>Scene Intrinsics and Depth from a Single Image</papertitle>
              </a>
              <br>
              <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
              <br>
              <em>ICCV Workshop</em>, 2015
              <br>
              <a href="data/Shelhamer2015.bib">bibtex</a>
              <p></p>
              <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0" onmouseout="defocus_stop()" onmouseover="defocus_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry' class='hidden'><img src="images/BarronCVPR2015_anim.gif"></div>
              <div id='lens_sharp'>
                <a href="images/BarronCVPR2015_anim.gif"><img src="images/BarronCVPR2015_still.jpg"></a>
              </div>
              <script type="text/javascript">
                function defocus_start() {
                  document.getElementById('lens_blurry').style.display = 'inline';
                  document.getElementById('lens_sharp').style.display = 'none';
                }

                function defocus_stop() {
                  document.getElementById('lens_blurry').style.display = 'none';
                  document.getElementById('lens_sharp').style.display = 'inline';
                }
                defocus_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1R4RdaBZIs-uJobhIFs9yKf3jIsaHQNH0/view?usp=sharing">
                <papertitle>Fast Bilateral-Space Stereo for Synthetic Defocus</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://people.csail.mit.edu/abadams/">Andrew Adams</a>, <a href="http://people.csail.mit.edu/yichangshih/">YiChang Shih</a>, <a href="http://carlos-hernandez.org/">Carlos Hern&aacutendez</a>
              <br>
              <em>CVPR</em>, 2015 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://drive.google.com/file/d/125qgMdqeT1vojMIijIKcOF099LjUgUOL/view?usp=sharing">abstract</a> /
              <a href="https://drive.google.com/file/d/1HGGvVOGxmPjvgdK5q3UD1Qb5Nttg6kq9/view?usp=sharing">supplement</a> /
              <a href="data/BarronCVPR2015.bib">bibtex</a> /
              <a href="http://techtalks.tv/talks/fast-bilateral-space-stereo-for-synthetic-defocus/61624/">talk</a> /
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSzZZdUJSMllSUkE/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmZ1ZXUzBCWDJYeFU">PDF</a>)
              <p></p>
              <p>By embedding a stereo optimization problem in "bilateral-space" we can very quickly solve for an edge-aware depth map, letting us render beautiful depth-of-field effects.</p>
              <p>This technology is used by the <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">Google Camera "Lens Blur"</a> feature. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/PABMM2015.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1EUvfslce9iqCbJ_IAE4J1ser6hpse_uh/view?usp=sharing" id="MCG_journal">
                <papertitle>Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation</papertitle>
              </a>
              <br>
              <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>TPAMI</em>, 2017
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
              <p></p>
              <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
              <p>This paper subsumes our CVPR 2014 paper.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0" onmouseout="sirfs_stop()" onmouseover="sirfs_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sirfs_image'>
                  <a href="images/Estee.png"><img src='images/Estee_160.png' style="border-style: none"></a>
                </div>
                <a href="images/Estee.png"><img src='images/Estee_160_prodB2.png' style="border-style: none"></a>
              </div>
              <script type="text/javascript">
                function sirfs_start() {
                  document.getElementById('sirfs_image').style.opacity = "1";
                }

                function sirfs_stop() {
                  document.getElementById('sirfs_image').style.opacity = "0";
                }
                sirfs_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <p>
                <a href="https://drive.google.com/file/d/1RvyCiDMg--jyO8lLBvopp0o271LvREoa/view?usp=sharing" id="SIRFS">
                  <papertitle>Shape, Illumination, and Reflectance from Shading</papertitle>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>TPAMI</em>, 2015
                <br>
                <a href="https://drive.google.com/file/d/1D3k6u4Ek2dWm2Yf7kl1Vu_g1HFSxztqF/view?usp=sharing">supplement</a> / <a href="data/BarronMalikTPAMI2015.bib">bibtex</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmVWpfa19mbUxIYW8/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmazJvLXJUb0NuM1U/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmTDBUWE96VHJndjg/view?usp=sharing">PDF</a>) / <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a> / <a href="https://drive.google.com/file/d/1vg9Rb-kBntSTnTCzVgFlskkPXvTB_5aq/view?usp=sharing">code &amp; data</a> / <a href="data/why_did_this_paper_come_out_in_2015.txt">rant</a> / <a href="https://drive.google.com/file/d/11X5Zfjy7Q7oP_V2rtqy2f5-x9YgQUAFd/view?usp=sharing">kudos</a>
              </p>
              <p>
                We present <strong>SIRFS</strong>, which can estimate shape, chromatic illumination, reflectance, and shading from a single image of an masked object.
              </p>
              <p>
                This paper subsumes our CVPR 2011, CVPR 2012, and ECCV 2012 papers.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ArbalaezCVPR2014.jpg" alt="ArbalaezCVPR2014" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1M0wijHY134F9ETBgO8mjeuKUSblTRLG0/view?usp=sharing">
                <papertitle>Multiscale Combinatorial Grouping</papertitle>
              </a>
              <br>
              <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>CVPR</em>, 2014
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/ArbelaezCVPR2014.bib">bibtex</a>
              <p>This paper is subsumed by <a href="#MCG_journal">our journal paper</a>.</p>
            </td>
          </tr>

          <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='flyspin' class='hidden'><img src="images/BarronICCV2013_160.gif"></div>
              <div id='flystill'>
                <a href="images/BarronICCV2013.gif"><img src="images/BarronICCV2013_160.jpg"></a>
              </div>
              <script type="text/javascript">
                function flyspin_start() {
                  document.getElementById('flyspin').style.display = 'inline';
                  document.getElementById('flystill').style.display = 'none';
                }

                function flyspin_stop() {
                  document.getElementById('flyspin').style.display = 'none';
                  document.getElementById('flystill').style.display = 'inline';
                }
                flyspin_stop()
              </script>
          </tr>

        </tbody></table>
                <br>
                Template credits to <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
